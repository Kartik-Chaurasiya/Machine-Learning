{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "breast_Cancer_MPneuron.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO/OW+A8uyaA3WoE3i66dd1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Syntax-code/Machine-Learning/blob/master/breast_Cancer_MPneuron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXSdxpexA3j8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiSluYWTBQEY",
        "colab_type": "text"
      },
      "source": [
        "Load breast cancer dataset from sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BvOUBnWBAxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "breast_cancer = sklearn.datasets.load_breast_cancer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E64MSJVCBPDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = breast_cancer.data\n",
        "Y = breast_cancer.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQBP2z3TCGgC",
        "colab_type": "code",
        "outputId": "bca51a45-228e-40ac-9b07-309b38e9b035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X.shape, Y.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 30) (569,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLDMbUuJEio-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
        "data['class'] = breast_cancer.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0taU-HVFC5f",
        "colab_type": "code",
        "outputId": "e19a55bc-43c2-4d8b-cbae-a31ee8d62dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst fractal dimension  class\n",
              "0        17.99         10.38  ...                  0.11890      0\n",
              "1        20.57         17.77  ...                  0.08902      0\n",
              "2        19.69         21.25  ...                  0.08758      0\n",
              "3        11.42         20.38  ...                  0.17300      0\n",
              "4        20.29         14.34  ...                  0.07678      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPcauqQbFVN-",
        "colab_type": "code",
        "outputId": "56e38756-8d44-43c6-da52-7a92bb363a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "      <td>0.627417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "      <td>0.483918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       mean radius  mean texture  ...  worst fractal dimension       class\n",
              "count   569.000000    569.000000  ...               569.000000  569.000000\n",
              "mean     14.127292     19.289649  ...                 0.083946    0.627417\n",
              "std       3.524049      4.301036  ...                 0.018061    0.483918\n",
              "min       6.981000      9.710000  ...                 0.055040    0.000000\n",
              "25%      11.700000     16.170000  ...                 0.071460    0.000000\n",
              "50%      13.370000     18.840000  ...                 0.080040    1.000000\n",
              "75%      15.780000     21.800000  ...                 0.092080    1.000000\n",
              "max      28.110000     39.280000  ...                 0.207500    1.000000\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NctOnLgsFccd",
        "colab_type": "code",
        "outputId": "404d032c-adf3-41c3-b1e5-961965b5e570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data['class'].unique()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnwPHtVkFjf-",
        "colab_type": "code",
        "outputId": "d93d86ea-6f89-48ac-adef-f8c321eaa751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "data['class'].value_counts()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    357\n",
              "0    212\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAxfGnczFyn1",
        "colab_type": "code",
        "outputId": "44526bdc-cd20-4c09-e6fe-425aa510ab5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "breast_cancer.target_names"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['malignant', 'benign'], dtype='<U9')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wes75rybF5Vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X =data.drop('class', axis=1)\n",
        "Y =data['class']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ojc_km2WKoUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X, Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOX20dS0VIxS",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Binarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp0wDTkvWPxF",
        "colab_type": "text"
      },
      "source": [
        "Cause the  MP neuron model takes input as binary values.\n",
        "\n",
        "Hence convert them into binary values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApwMd05rVTcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_binarized_train = X_train.apply(pd.cut, bins= 2, labels = [1,0])\n",
        "X_binarized_test = X_test.apply(pd.cut, bins= 2, labels = [1,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oHDgTPJVyM2",
        "colab_type": "code",
        "outputId": "b0927ae4-ad74-4738-efd3-d700db3a5393",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(X_binarized_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5OD4-OvWDvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_binarized_train = X_binarized_train.values\n",
        "X_binarized_test = X_binarized_test.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EsQt9MWWMpn",
        "colab_type": "code",
        "outputId": "7aaf1e2f-d9b1-4d70-c839-9319ba8487d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(X_binarized_train)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnV9gKQcqTkk",
        "colab_type": "text"
      },
      "source": [
        "Mp neuron model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRfz5uMfqWZB",
        "colab_type": "code",
        "outputId": "b452decd-3ea0-4912-9135-7427d2cad861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "b = 3\n",
        "\n",
        "i = 100\n",
        "\n",
        "if np.sum(X_binarized_train[i, :]) >= b:\n",
        "  print('MP neuron model is malignant')\n",
        "else:\n",
        "  print('MP neuron model is benign')\n",
        "\n",
        "if (Y_train[i] == 1) :\n",
        "  print('It is malignant')\n",
        "else:\n",
        "  print('It is benign')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MP neuron model is malignant\n",
            "It is benign\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHm2bjhssfBB",
        "colab_type": "code",
        "outputId": "e4549d7f-ee12-4ca2-e05a-21019b5d59a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "b = 3\n",
        "\n",
        "i = randint(0, X_binarized_train.shape[0])\n",
        "\n",
        "print('For row ', i )\n",
        "\n",
        "if np.sum(X_binarized_train[i, :]) >= b:\n",
        "  print('MP neuron model is malignant')\n",
        "else:\n",
        "  print('MP neuron model is benign')\n",
        "\n",
        "if (Y_train[i] == 1) :\n",
        "  print('It is malignant')\n",
        "else:\n",
        "  print('It is benign')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For row  121\n",
            "MP neuron model is malignant\n",
            "It is benign\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ0MkalktYf5",
        "colab_type": "code",
        "outputId": "fb6713b2-e6ff-4190-9c3f-6847e0ec42fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b= 3\n",
        "Y_pred_train = []\n",
        "accurate = 0\n",
        "\n",
        "for x,y in zip(X_binarized_train, Y_train):\n",
        "  Y_pred = (np.sum(x) >= b)\n",
        "  Y_pred_train.append(Y_pred)\n",
        "  accurate += (y == Y_pred ) \n",
        "\n",
        "print(accurate/X_binarized_train.shape[0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5985915492957746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L_FongDvTmQ",
        "colab_type": "code",
        "outputId": "359eb4f5-0a5d-4359-98c7-8666b1ae3f01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "for b in range(X_binarized_train.shape[1] + 1):\n",
        "  Y_pred_train = []\n",
        "  accurate = 0\n",
        "\n",
        "  for x,y in zip(X_binarized_train, Y_train):\n",
        "    Y_pred = (np.sum(x) >= b)\n",
        "    Y_pred_train.append(Y_pred)\n",
        "    accurate += (y == Y_pred ) \n",
        "\n",
        "  print(b , accurate/X_binarized_train.shape[0])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.5985915492957746\n",
            "1 0.5985915492957746\n",
            "2 0.5985915492957746\n",
            "3 0.5985915492957746\n",
            "4 0.5985915492957746\n",
            "5 0.5985915492957746\n",
            "6 0.5985915492957746\n",
            "7 0.5985915492957746\n",
            "8 0.5985915492957746\n",
            "9 0.5985915492957746\n",
            "10 0.5985915492957746\n",
            "11 0.5985915492957746\n",
            "12 0.596244131455399\n",
            "13 0.5938967136150235\n",
            "14 0.5985915492957746\n",
            "15 0.5985915492957746\n",
            "16 0.5985915492957746\n",
            "17 0.596244131455399\n",
            "18 0.5868544600938967\n",
            "19 0.5845070422535211\n",
            "20 0.5821596244131455\n",
            "21 0.5868544600938967\n",
            "22 0.5774647887323944\n",
            "23 0.568075117370892\n",
            "24 0.5704225352112676\n",
            "25 0.5563380281690141\n",
            "26 0.5586854460093896\n",
            "27 0.5516431924882629\n",
            "28 0.539906103286385\n",
            "29 0.5046948356807511\n",
            "30 0.4835680751173709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WOv0RpdxCGH",
        "colab_type": "code",
        "outputId": "eef52f2f-bb0d-4f4b-f03e-30d6898cd680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b= 27\n",
        "Y_pred_test =[]\n",
        "\n",
        "for x in X_binarized_test :\n",
        "  Y_pred = (np.sum(x) >= b)\n",
        "  Y_pred_test.append(Y_pred)\n",
        "\n",
        "accuracy = accuracy_score(Y_pred_test, Y_test)\n",
        "\n",
        "print(b, accuracy)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27 0.6363636363636364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Zeek7aff4nq",
        "colab_type": "text"
      },
      "source": [
        "##Class for MP neuron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSjxnWKqf3qQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mp_neuron:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.b = None\n",
        "\n",
        "  def model(self, x):\n",
        "    return(sum(x) >= self.b)\n",
        "  \n",
        "  def predict(self, X):\n",
        "    y = []\n",
        "    for x in X:\n",
        "      result = self.model(x)\n",
        "      y.append(result)\n",
        "    return np.array(y)\n",
        "\n",
        "  def fit(self, X, Y):\n",
        "    accuracy = {}\n",
        "\n",
        "    for b in range(X.shape[1] + 1):\n",
        "      self.b = b\n",
        "      Y_pred = self.predict(X)\n",
        "      accuracy[b] = accuracy_score(Y_pred, Y)\n",
        "    \n",
        "    best_b = max(accuracy, key = accuracy.get)\n",
        "    self.b = best_b\n",
        "\n",
        "    print('Optimal value of b', best_b)\n",
        "    print('highest accuracy' , accuracy[best_b])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDegQls2l06r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "87411386-03e0-44fc-8388-ec078c4b9fd4"
      },
      "source": [
        "mp_neuron = Mp_neuron()\n",
        "mp_neuron.fit(X_binarized_train, Y_train)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimal value of b 0\n",
            "highest accuracy 0.5985915492957746\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}